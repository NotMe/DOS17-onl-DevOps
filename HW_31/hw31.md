## 1

Работа с Google Cloud Storage (GCS):
- Создать GCE, открыть SSH сессию в созданную VM.
- Cклонировать репозиторий и ознакомиться с проектом и инструкцией к нему.
- Создать необходимые ресурсы для работы приложения:
- Создать GCS Bucket <LASTNAME>-gcs-demo.
- Создать Service Account <LASTNAME>-gcs-demo и назначьте ему роль Storage Object Admin (IAM & Admin -> IAM -> GRANT ACCESS)
- Сгенерировать и скачать Service Account Key в формате JSON.
- Установить Node.js 18.
- Установить зависимости приложения через NPM.
- Поправить имя GCS Bucket и имя файла с Service Account Key в каком-то из .js файлов приложения.
- Запустить приложение и проверить его работоспособность путем выполнение нескольких HTTP запросов через Postman как описано в Node.js upload File to Google Cloud Storage example параграфе.

```
# git clone https://github.com/Azizahmed1/FileUploadAwsS3.git

настраиваю и запускаю backend

# cd ./FileUploadAwsS3/backend
# cat .env
AWS_BUCKET_NAME=tms-dos17-onl
AWS_BUCKET_REGION=eu-north-1
AWS_ACCESS_KEY=AKIAUPRZNWHMOB32QOY2
AWS_SECRET_KEY=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

# npm install
# npm run start
> backend@1.0.0 start
> node server.js

listening on port 8080


запускаю frontend
# cd ./FileUploadAwsS3/frontend
# npm install
# npm install postcss
# npm audit fix --force
# npm run start
Compiled successfully!

You can now view frontend in the browser.

  Local:            http://localhost:3000
  On Your Network:  http://172.31.24.201:3000

Note that the development build is not optimized.
To create a production build, use yarn build.

webpack compiled successfully
```
![plot](./pics/app.png)
```
после нажатия на кнопку Submit в логах backend следующее
{
  fieldname: 'image',
  originalname: 'clouds2.jpg',
  encoding: '7bit',
  mimetype: 'image/jpeg',
  destination: 'uploads/',
  filename: '58b505e2eb3c52003b9491846fc13a7b',
  path: 'uploads/58b505e2eb3c52003b9491846fc13a7b',
  size: 57855
}
{
  ETag: '"fc1724e2ebe8a866acaceae50af0d4d0"',
  ServerSideEncryption: 'AES256',
  Location: 'https://tms-dos17-onl.s3.eu-north-1.amazonaws.com/58b505e2eb3c52003b9491846fc13a7b',
  key: '58b505e2eb3c52003b9491846fc13a7b',
  Key: '58b505e2eb3c52003b9491846fc13a7b',
  Bucket: 'tms-dos17-onl'
}

этот же файл (58b505e2eb3c52003b9491846fc13a7b) появился и в s3 bucket
```
![plot](./pics/aws_s3.png)

И видно, что созданный пользователь с IAM ролью был в этот момент использован
![plot](./pics/aws_s3_IAM.png)


## 2

Настройка автомасштабирования:
- Создать шаблон виртуальной машины apache-php-template:
- Активировать Allow HTTP traffic.
- В качестве startup скрипта написать команды для установки Apache веб-сервера с поддержкой PHP и создания phpinfo страницы (<?php phpinfo(); ?>).
- Создать группу виртуальных машин apache-php-group с помощью шаблона apache-php-template:
- Использовать мультизональную локацию.
- Настроить автомасштабирование от 2 до 4 экземпляров.
- Понизить порог для автомасштабирования до 30% CPU.
- Создать Application Load Balancer:
- В качестве Backend использовать ранее созданную группу VM apache-php-group:
- Выключить Cloud CDN.
- В качестве, Health Check использовать просто проверку доступности домашней страницы Apache.
- Проверить распределение трафика путем выполнения HTTP запроса GET /index.php через Load Balancer и сравнения свойства SERVER_ADDR в phpinfo таблице.
- Сгенерировать нагрузку на Load Balancer и убедиться, что работает автомасштабирование.

```

```
![plot](./pics/aws_template_startup_script.png)
![plot](./pics/aws_ASG.png)
![plot](./pics/aws_SG.png)
![plot](./pics/aws_first_instances.png)
![plot](./pics/aws_LB.png)
![plot](./pics/aws_LB_1.png)
![plot](./pics/aws_LB_2.png)
![plot](./pics/aws_stress_1.png)
![plot](./pics/aws_LB_increase_capacity.png)
![plot](./pics/aws_ASG_increase_capacity.png)
![plot](./pics/aws_started_instances.png)

